{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d892a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from mytools import Video, get_cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd226ec",
   "metadata": {},
   "source": [
    "# Extract cuts and noncuts from videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636e18f",
   "metadata": {},
   "source": [
    "## Prepare directories for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0814e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'data'\n",
    "path_cuts = os.path.join(path_data, 'cuts')\n",
    "path_noncuts = os.path.join(path_data, 'noncuts')\n",
    "\n",
    "if os.path.exists(path_data):\n",
    "    shutil.rmtree(path_data)\n",
    "if os.path.exists(path_cuts):\n",
    "    shutil.rmtree(path_cuts)\n",
    "if os.path.exists(path_noncuts):\n",
    "    shutil.rmtree(path_noncuts)\n",
    "\n",
    "os.makedirs(path_data)\n",
    "os.makedirs(path_cuts)\n",
    "os.makedirs(path_noncuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d348cad",
   "metadata": {},
   "source": [
    "## Extracting cuts from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d535f5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 90)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size = (640, 360)\n",
    "output_size = (320, 180)\n",
    "output_size = (160, 90)\n",
    "output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d301ea",
   "metadata": {},
   "source": [
    "### Video 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7580576",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_timeline0 = 'timelines/0.kdenlive'\n",
    "path_video0 = 'videos/0.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66afa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video0.length = 5875\n"
     ]
    }
   ],
   "source": [
    "video0 = Video(path_video0)\n",
    "cuts0 = get_cuts(path_timeline0)\n",
    "\n",
    "print(f'video0.length = {video0.length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4460616d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3521fa4f45da453392441943e8dc9216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video = video0\n",
    "cuts = cuts0\n",
    "filename_template = '0-{0}.gif'\n",
    "\n",
    "for i in tqdm(range(len(cuts)), total=len(cuts)):\n",
    "    filename = filename_template.format(i)\n",
    "    frames = video.get_matrix(cuts[i]-2, cuts[i]+2)\n",
    "    images = [Image.fromarray(frame).resize(output_size) for frame in frames]\n",
    "    imageio.mimsave(os.path.join(path_cuts, filename), images, fps=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb67da",
   "metadata": {},
   "source": [
    "### Video 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8781e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_timeline1 = 'timelines/1.kdenlive'\n",
    "path_video1 = 'videos/1.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dcb321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video1.length = 5750\n"
     ]
    }
   ],
   "source": [
    "video1 = Video(path_video1)\n",
    "cuts1 = get_cuts(path_timeline1)\n",
    "\n",
    "print(f'video1.length = {video1.length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c0ba14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ed662a4a764cac98f7ede5cb6b0322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video = video1\n",
    "cuts = cuts1\n",
    "filename_template = '1-{0}.gif'\n",
    "\n",
    "for i in tqdm(range(len(cuts)), total=len(cuts)):\n",
    "    filename = filename_template.format(i)\n",
    "    frames = video.get_matrix(cuts[i]-2, cuts[i]+2)\n",
    "    images = [Image.fromarray(frame).resize(output_size) for frame in frames]\n",
    "    imageio.mimsave(os.path.join(path_cuts, filename), images, fps=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61519a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 391 real cut examples extracted to data/cuts\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(os.listdir(path_cuts))} real cut examples extracted to {path_cuts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b180f52d",
   "metadata": {},
   "source": [
    "## Extracting noncuts from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46d8e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5419 possible noncat inputs for video1.\n"
     ]
    }
   ],
   "source": [
    "noncut_inputs0 = np.unique(np.concatenate([[0, video0.length], cuts0]))\n",
    "noncut_inputs0 = [np.arange(noncut_inputs0[i], noncut_inputs0[i+1]-3) for i in range(len(noncut_inputs0)-1)]\n",
    "noncut_inputs0 = np.concatenate(noncut_inputs0)\n",
    "print(f'There are {len(noncut_inputs0)} possible noncat inputs for video1.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd80a908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5047 possible noncat inputs for video1.\n"
     ]
    }
   ],
   "source": [
    "noncut_inputs1 = np.unique(np.concatenate([[0, video1.length], cuts1]))\n",
    "noncut_inputs1 = [np.arange(noncut_inputs1[i], noncut_inputs1[i+1]-3) for i in range(len(noncut_inputs1)-1)]\n",
    "noncut_inputs1 = np.concatenate(noncut_inputs1)\n",
    "print(f'There are {len(noncut_inputs1)} possible noncat inputs for video1.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04188658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portion of cuts is 3.60%\n"
     ]
    }
   ],
   "source": [
    "number_of_cuts = len(cuts0) + len(cuts1)\n",
    "number_of_noncuts = len(noncut_inputs0) + len(noncut_inputs1)\n",
    "print('Portion of cuts is {0:.2f}%'.format(100*number_of_cuts/(number_of_noncuts + number_of_cuts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff76357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will use 4185 noncuts.\n"
     ]
    }
   ],
   "source": [
    "noncut_use_portion = 0.4\n",
    "noncut_inputs_use0 = np.sort(np.random.choice(noncut_inputs0, int(noncut_use_portion*len(noncut_inputs0)), replace=False))\n",
    "noncut_inputs_use1 = np.sort(np.random.choice(noncut_inputs1, int(noncut_use_portion*len(noncut_inputs1)), replace=False))\n",
    "\n",
    "print(f'I will use {len(noncut_inputs_use0) + len(noncut_inputs_use1)} noncuts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cb570d",
   "metadata": {},
   "source": [
    "Can extract more, using `noncut_use_portion` variable. If `noncut_use_portion = 1` extract all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "230092da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d841c0f4acf84c55ab1157942a3b5ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noncut_inputs = noncut_inputs_use0\n",
    "video = video0\n",
    "filename_template = '0-{0}.gif'\n",
    "\n",
    "for i in tqdm(range(len(noncut_inputs)), total=len(noncut_inputs)):\n",
    "    filename = filename_template.format(i)\n",
    "    frames = video.get_matrix(noncut_inputs[i], noncut_inputs[i]+4)\n",
    "    images = [Image.fromarray(frame).resize(output_size) for frame in frames]\n",
    "    imageio.mimsave(os.path.join(path_noncuts, filename), images, fps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cd45edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaf9d93ffa849c5abff7a8612c6caaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2018 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noncut_inputs = noncut_inputs_use1\n",
    "video = video1\n",
    "filename_template = '1-{0}.gif'\n",
    "\n",
    "for i in tqdm(range(len(noncut_inputs)), total=len(noncut_inputs)):\n",
    "    filename = filename_template.format(i)\n",
    "    frames = video.get_matrix(noncut_inputs[i], noncut_inputs[i]+4)\n",
    "    images = [Image.fromarray(frame).resize(output_size) for frame in frames]\n",
    "    imageio.mimsave(os.path.join(path_noncuts, filename), images, fps=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6540ee",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fb76207",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_validation = os.path.join(path_data, 'validation')\n",
    "path_validation_cuts = os.path.join(path_validation, 'cuts')\n",
    "path_validation_noncuts = os.path.join(path_validation, 'noncuts')\n",
    "\n",
    "path_training = os.path.join(path_data, 'training')\n",
    "path_training_cuts = os.path.join(path_training, 'cuts')\n",
    "path_training_noncuts = os.path.join(path_training, 'noncuts')\n",
    "\n",
    "if os.path.exists(path_validation):\n",
    "    shutil.rmtree(path_validation)\n",
    "if os.path.exists(path_training):\n",
    "    shutil.rmtree(path_training)\n",
    "    \n",
    "os.makedirs(path_validation)\n",
    "os.makedirs(path_validation_cuts)\n",
    "os.makedirs(path_validation_noncuts)\n",
    "\n",
    "os.makedirs(path_training)\n",
    "os.makedirs(path_training_cuts)\n",
    "os.makedirs(path_training_noncuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f441440",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_parameter = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77c4f0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy training cuts:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9280ad41e7429c952bd0a0dd93b8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy validation cuts:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dbeaf141444450be4b0267b6f12d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filenames_cuts = os.listdir(path_cuts)\n",
    "np.random.shuffle(filenames_cuts)\n",
    "\n",
    "filenames_cuts_training = filenames_cuts[:int(split_parameter*len(filenames_cuts))]\n",
    "filenames_cuts_validation = filenames_cuts[int(split_parameter*len(filenames_cuts)):]\n",
    "\n",
    "print('Copy training cuts:')\n",
    "for filename in tqdm(filenames_cuts_training, total=len(filenames_cuts_training)):\n",
    "    shutil.copyfile(os.path.join(path_cuts, filename), os.path.join(path_training_cuts, filename))\n",
    "    \n",
    "print('Copy validation cuts:')\n",
    "for filename in tqdm(filenames_cuts_validation, total=len(filenames_cuts_validation)):\n",
    "    shutil.copyfile(os.path.join(path_cuts, filename), os.path.join(path_validation_cuts, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2662883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy training noncuts:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c2f300926b4d72a79e1f2ea125e370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy validation noncuts:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded3479a0a6b436f8d76b621f81e9387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filenames_noncuts = os.listdir(path_noncuts)\n",
    "np.random.shuffle(filenames_noncuts)\n",
    "\n",
    "filenames_noncuts_training = filenames_noncuts[:int(split_parameter*len(filenames_noncuts))]\n",
    "filenames_noncuts_validation = filenames_noncuts[int(split_parameter*len(filenames_noncuts)):]\n",
    "\n",
    "print('Copy training noncuts:')\n",
    "for filename in tqdm(filenames_noncuts_training, total=len(filenames_noncuts_training)):\n",
    "    shutil.copyfile(os.path.join(path_noncuts, filename), os.path.join(path_training_noncuts, filename))\n",
    "    \n",
    "print('Copy validation noncuts:')\n",
    "for filename in tqdm(filenames_noncuts_validation, total=len(filenames_noncuts_validation)):\n",
    "    shutil.copyfile(os.path.join(path_noncuts, filename), os.path.join(path_validation_noncuts, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace3c6a",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72074383",
   "metadata": {},
   "source": [
    "## Augmentation Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "767135ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to create 843 augmentated cuts.\n",
      "Then portion of cuts in training_data will be 25.65 %\n"
     ]
    }
   ],
   "source": [
    "portion_augmentated = 0.73\n",
    "\n",
    "number_training_cuts = len(os.listdir(path_training_cuts))\n",
    "number_training_noncuts = len(os.listdir(path_training_noncuts))\n",
    "\n",
    "number_augmentated = int(number_training_cuts*portion_augmentated/(1 - portion_augmentated))\n",
    "\n",
    "print(f'I am going to create {number_augmentated} augmentated cuts.')\n",
    "print('Then portion of cuts in training_data will be {0:.2f} %'.format(100*(number_augmentated + number_training_cuts)/(number_augmentated + number_training_cuts + number_training_noncuts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34f8f0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f3393cf2024b45a2a5561ee2f7de3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/843 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename_template = 'a-{0}.gif'\n",
    "videos = [video0, video1]\n",
    "inputs = [noncut_inputs0, noncut_inputs1]\n",
    "\n",
    "for i in tqdm(range(number_augmentated)):\n",
    "    filename = filename_template.format(i)\n",
    "    \n",
    "    id0 = np.random.randint(2)\n",
    "    id1 = np.random.randint(2)\n",
    "    input0 = np.random.choice(inputs[id0])\n",
    "    input1 = np.random.choice(inputs[id1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    while (input1 == input0 + 2) and (id0 == id1):\n",
    "        # Change if noncut randomly got\n",
    "        print('noncut randomly got once')\n",
    "        id0 = np.random.randint(2)\n",
    "        id1 = np.random.randint(2)\n",
    "        input0 = np.random.choice(inputs[id0])\n",
    "        input1 = np.random.choice(inputs[id1])\n",
    "    \n",
    "    frames0 = videos[id0].get_matrix(input0, input0 + 2)\n",
    "    frames1 = videos[id1].get_matrix(input1, input1 + 2)\n",
    "    frames = np.concatenate([frames0, frames1])\n",
    "    \n",
    "    images = [Image.fromarray(frame).resize(output_size) for frame in frames]\n",
    "    imageio.mimsave(os.path.join(path_training_cuts, filename), images, fps=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25580c5a",
   "metadata": {},
   "source": [
    "I built an augmentation for cuts. But there are 2 problems:\n",
    "\n",
    "1. I will need to upload gif every iteration, if I'll use that. And this is not good, because that can be too long.\n",
    "2. There are not realy many situations.\n",
    "\n",
    "The first problem can be solved, by developing generator from videos and timelines. I will download each video only once and then extract cut and noncut moments, using some pd.DataFrame file.\n",
    "\n",
    "There are few steps how to build that:\n",
    "1. Add methods to mytools.Video, which will extract images, not arrays.\n",
    "2. Develop a table format to store a cut and noncut info\n",
    "3. Develop a function or class, which will extract array shape (4, width, height, 3) from given row\n",
    "4. Develop a generator, which will use a function or class from 3\n",
    "\n",
    "The 2nd problem can be easilly solved by adding flips, zooms and reverses to both: cuts and noncuts. But that will be harder if add this to steps 2-4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03c011",
   "metadata": {},
   "source": [
    "The function or class from step 3 can read unique filenames from `video` and `timeline` raws of table from step 1, and then upload them using `mytools.Video`, `mytools.get_timeline` to dictionaries, which keys are this filenames."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
