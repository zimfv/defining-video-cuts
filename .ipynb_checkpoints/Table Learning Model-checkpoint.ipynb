{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a69b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 05:34:43.967075: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 05:34:44.027539: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-27 05:34:44.027595: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-27 05:34:44.027651: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-27 05:34:44.038241: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 05:34:44.038949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 05:34:45.141899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from mytools import Video, get_cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728fdf5",
   "metadata": {},
   "source": [
    "# Define Spliter and Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4322c",
   "metadata": {},
   "source": [
    "## Used functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a233f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cuts_df(video, cuts, frames_before=2, frames_after=2):\n",
    "    \"\"\"\n",
    "    Returns table of frames indices arround cuts.\n",
    "    \n",
    "    Parameters:\n",
    "    video : mytools.Video\n",
    "    \n",
    "    cuts : int-array\n",
    "    \n",
    "    frames_before : int\n",
    "    \n",
    "    frames_after : int\n",
    "    \"\"\"\n",
    "    df = np.arange(-frames_before, frames_after).reshape([1, frames_before + frames_after]) + cuts.reshape([len(cuts), 1])\n",
    "    df = pd.DataFrame(df).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf344b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noncuts_df(video, cuts, frames_before=2, frames_after=2):\n",
    "    \"\"\"\n",
    "    Returns table of frames indices arround noncuts.\n",
    "    \n",
    "    Parameters:\n",
    "    video : mytools.Video\n",
    "    \n",
    "    cuts : int-array\n",
    "    \n",
    "    frames_before : int\n",
    "    \n",
    "    frames_after : int\n",
    "    \"\"\"\n",
    "    noncuts = np.arange(len(video))\n",
    "    noncuts = noncuts[np.logical_not(np.isin(noncuts, cuts))]\n",
    "    noncuts = noncuts[noncuts >= frames_before]\n",
    "    noncuts = noncuts[noncuts < len(video) - frames_after]\n",
    "    df = np.arange(-frames_before, frames_after).reshape([1, frames_before + frames_after]) + noncuts.reshape([len(noncuts), 1])\n",
    "    df = pd.DataFrame(df).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b7a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_from_row(row, videos, frames_before=2, frames_after=2, video_size=None, rescale=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i in range(frames_before):\n",
    "        res.append(videos[row['before']].get_frame(row[i], new_size=video_size))\n",
    "    for i in range(frames_before, frames_before + frames_after):\n",
    "        res.append(videos[row['after']].get_frame(row[i], new_size=video_size))\n",
    "    res = np.array(res)\n",
    "    if rescale is not None:\n",
    "        res = res*rescale\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf36737",
   "metadata": {},
   "source": [
    "## Iterator and Generator classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a18e51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableVideoIterator:\n",
    "    def __init__(self, videos, df: pd.DataFrame, frames_before=2, frames_after=2, \n",
    "                 batch_size=64, video_size=None, rescale=None, shuffle=True):\n",
    "        \"\"\"\n",
    "        Yields batches (X, y)\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        videos : dict, with mytools.Video values\n",
    "        \n",
    "        df : pd.DataFrame, columns: 'before' - str, videos keys\n",
    "                                    'after' - str, videos keys\n",
    "                                    'cut' - bool, \n",
    "                                    0, 1, ..., (frames_before + frames_after - 1) - int\n",
    "        \n",
    "        frames_before : int\n",
    "        \n",
    "        frames_after : int\n",
    "        \n",
    "        batch_size : int\n",
    "        \n",
    "        video_size : None or tuple with 2 integers\n",
    "            Change video size if not None\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        self.videos = videos\n",
    "        self.df = df.reset_index(drop=False)\n",
    "        self.frames_before = frames_before\n",
    "        self.frames_after = frames_after\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.rescale = rescale\n",
    "        self.video_size = video_size\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        self.batch_index = 0\n",
    "        \n",
    "    def reshuffle(self):\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (len(self.df) - 1)//self.batch_size + 1\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.batch_index = 0\n",
    "        self.reshuffle()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self):\n",
    "            raise ValueError(\n",
    "                \"Asked to retrieve element {idx}, \"\n",
    "                \"but the Sequence \"\n",
    "                \"has length {length}\".format(idx=idx, length=len(self))\n",
    "            )\n",
    "        if idx == len(self) - 1:\n",
    "            indexes_i = self.indexes[idx*self.batch_size:]\n",
    "        else:\n",
    "            indexes_i = self.indexes[idx*self.batch_size:(idx + 1)*self.batch_size]\n",
    "        X = []\n",
    "        for i in indexes_i:\n",
    "            X.append(get_frames_from_row(self.df.loc[i], self.videos, \n",
    "                                         frames_before=self.frames_before, \n",
    "                                         frames_after=self.frames_after, \n",
    "                                         video_size=self.video_size, \n",
    "                                         rescale=self.rescale))\n",
    "        X = np.array(X)\n",
    "        y = self.df.loc[indexes_i, 'cut'].values.astype(int)\n",
    "        return X, y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.batch_index += 1\n",
    "        if self.batch_index > len(self):\n",
    "            self.on_epoch_end()\n",
    "            raise StopIteration\n",
    "        return self[self.batch_index - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05cdc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableVideoGenerator:\n",
    "    def __init__(self, videos, df: pd.DataFrame, frames_before=2, frames_after=2, \n",
    "                 batch_size=64, video_size=None, rescale=None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.videos = videos\n",
    "        self.df = df.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.rescale = rescale\n",
    "        self.video_size = video_size\n",
    "        self.frames_before = frames_before\n",
    "        self.frames_after = frames_after\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.df) - 1)//self.batch_size + 1\n",
    "    \n",
    "    def flow(self):\n",
    "        while True:\n",
    "            for X, y in TableVideoIterator(videos=self.videos, df=self.df, \n",
    "                                           frames_before=self.frames_before, frames_after=self.frames_after, \n",
    "                                           batch_size=self.batch_size, \n",
    "                                           video_size=self.video_size, rescale=self.rescale, shuffle=True):\n",
    "                yield X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7405d9",
   "metadata": {},
   "source": [
    "## Spliter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8522977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spliter:\n",
    "    def __init__(self, video_paths, cuts_paths, frames_before=2, frames_after=2):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if len(video_paths) != len(cuts_paths):\n",
    "            raise ValueError(\"video_paths and cuts_paths have different lengths.\")\n",
    "        self.frames_before = frames_before\n",
    "        self.frames_after = frames_after\n",
    "        self.filenames = np.array(video_paths)\n",
    "        self.videos = {}\n",
    "        self.cuts = {}\n",
    "        for i in range(len(video_paths)):\n",
    "            self.videos.update({video_paths[i] : Video(video_paths[i])})\n",
    "            self.cuts.update({video_paths[i] : get_cuts(cuts_paths[i])})\n",
    "        self.df = pd.DataFrame(columns=['before', 'after', 'cut'])\n",
    "        self.df = self.df.astype({'before' : str, 'after' : str, 'cut' : bool})\n",
    "    \n",
    "    def define_cuts(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for filename in self.filenames:\n",
    "            dfi = get_cuts_df(self.videos[filename], self.cuts[filename], \n",
    "                              frames_before=self.frames_before, frames_after=self.frames_after)\n",
    "            dfi['cut'] = True\n",
    "            dfi['before'] = filename\n",
    "            dfi['after'] = filename\n",
    "            self.df = pd.concat([self.df, dfi], ignore_index=True)\n",
    "        for i in range(self.frames_before + self.frames_after):\n",
    "            self.df = self.df.astype({i: int})\n",
    "            \n",
    "    def define_noncuts(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for filename in self.filenames:\n",
    "            dfi = get_noncuts_df(self.videos[filename], self.cuts[filename], \n",
    "                                 frames_before=self.frames_before, frames_after=self.frames_after)\n",
    "            dfi['cut'] = False\n",
    "            dfi['before'] = filename\n",
    "            dfi['after'] = filename\n",
    "            self.df = pd.concat([self.df, dfi], ignore_index=True)\n",
    "        for i in range(self.frames_before + self.frames_after):\n",
    "            self.df = self.df.astype({i: int})\n",
    "            \n",
    "    def define(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.define_cuts()\n",
    "        self.define_noncuts()\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        \n",
    "    def split(self, validation_portion=0.2):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        n = int(len(self.df)*validation_portion)\n",
    "        idx = self.df.index.values\n",
    "        np.random.shuffle(idx)\n",
    "        self.df_validation = pd.DataFrame(self.df.values[idx[:n]], columns=self.df.columns)\n",
    "        self.df_training = pd.DataFrame(self.df.values[idx[n:]], columns=self.df.columns)\n",
    "    \n",
    "    \n",
    "    def len_training_cuts(self):\n",
    "        # return number of cut-rows in training table\n",
    "        return len(self.df_training[self.df_training['cut'] == True])\n",
    "    \n",
    "    def len_training_noncuts(self):\n",
    "        # return number of noncut-rows in training table\n",
    "        return len(self.df_training[self.df_training['cut'] == False])\n",
    "    \n",
    "    def len_validation_cuts(self):\n",
    "        # return number of cut-rows in validation table\n",
    "        return len(self.df_validation[self.df_validation['cut'] == True])\n",
    "    \n",
    "    def len_validation_noncuts(self):\n",
    "        # return number of noncut-rows in validation table\n",
    "        return len(self.df_validation[self.df_validation['cut'] == False])\n",
    "    \n",
    "    \n",
    "    def augment_cuts(self, n=0, near_val=2):\n",
    "        \"\"\"\n",
    "        Add augmentated cuts to training table.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n : int\n",
    "            Number of augmneting and adding cut-rows.\n",
    "        \n",
    "        near_val : int\n",
    "            If cut is got from one video and the neighbou frames are in destace less n in original: remove that cut-rows.\n",
    "        \"\"\"\n",
    "        df_noncut = self.df_training[self.df_training['cut'] == False].reset_index(drop=True)\n",
    "        begins = np.random.randint(len(df_noncut), size=[n, 2])\n",
    "        df_before = df_noncut.loc[begins[:, 0], np.append('before', np.arange(self.frames_before, dtype=object))].reset_index(drop=True)\n",
    "        df_after = df_noncut.loc[begins[:, 1], np.append('after', np.arange(self.frames_before, self.frames_before + self.frames_after, dtype=object))].reset_index(drop=True)\n",
    "        df_augcut = pd.concat([df_before,df_after], axis=1)\n",
    "        df_augcut['cut'] = True\n",
    "        df_augcut = df_augcut[np.concatenate([['before', 'after', 'cut'], np.arange(self.frames_before + self.frames_after, dtype=object)])]\n",
    "        df_augcut = df_augcut.astype({'cut' : bool})\n",
    "        near = (abs(df_augcut[self.frames_before] - df_augcut[self.frames_before - 1]) < near_val) & (df_augcut['before'] == df_augcut['after'])\n",
    "        if len(df_augcut[near]) != 0:\n",
    "            msg = f'\\nGot {len(df_augcut[near])} extremly near cut rows:\\n' \n",
    "            msg += str(df_augcut[near])\n",
    "            df_augcut = df_augcut[np.logical_not(near)]\n",
    "            msg += '\\nSo removed them.'\n",
    "            warnings.warn(msg)\n",
    "            \n",
    "        \n",
    "        self.df_training = self.df_training.astype({'cut' : bool})\n",
    "        self.df_training = pd.concat([self.df_training, df_augcut]).reset_index(drop=True)\n",
    "        self.df_training = shuffle(self.df_training)\n",
    "        \n",
    "    def get_validation_generator(self, batch_size=16, video_size=(160, 90), rescale=1/255):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return TableVideoGenerator(videos=self.videos, df=self.df_validation, \n",
    "                                   frames_before=self.frames_before, frames_after=self.frames_after, \n",
    "                                   batch_size=batch_size, video_size=video_size, rescale=rescale)\n",
    "    \n",
    "    def get_training_generator(self, batch_size=64, video_size=(160, 90), rescale=1/255):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return TableVideoGenerator(videos=self.videos, df=self.df_training, \n",
    "                                   frames_before=self.frames_before, frames_after=self.frames_after, \n",
    "                                   batch_size=batch_size, video_size=video_size, rescale=rescale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64eefe",
   "metadata": {},
   "source": [
    "# Aigment and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4dcc513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spliter = Spliter(['videos/{0}.mp4'.format(i) for i in range(2)], \n",
    "                  ['timelines/{0}.kdenlive'.format(i) for i in range(2)], \n",
    "                  frames_before=2, frames_after=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25960e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set length is 2323: 78 cuts vs 2245 noncuts\n",
      "Training set length is 9294: 313 cuts vs 8981 noncuts\n"
     ]
    }
   ],
   "source": [
    "spliter.define()\n",
    "spliter.split()\n",
    "\n",
    "print('Validation set length is {0}: {1} cuts vs {2} noncuts'.format(len(spliter.df_validation), \n",
    "                                                                       spliter.len_validation_cuts(), \n",
    "                                                                       spliter.len_validation_noncuts()))\n",
    "print('Training set length is {0}: {1} cuts vs {2} noncuts'.format(len(spliter.df_training), \n",
    "                                                                       spliter.len_training_cuts(), \n",
    "                                                                       spliter.len_training_noncuts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5b3bf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length is 17959: 8978 cuts vs 8981 noncuts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10266/1062479671.py:104: UserWarning: \n",
      "Got 3 extremly near cut rows:\n",
      "            before         after   cut     0     1     2     3\n",
      "4850  videos/0.mp4  videos/0.mp4  True  2685  2686  2687  2688\n",
      "7943  videos/0.mp4  videos/0.mp4  True  2901  2902  2903  2904\n",
      "8487  videos/1.mp4  videos/1.mp4  True  2602  2603  2603  2604\n",
      "So removed them.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "spliter.augment_cuts(n=spliter.len_training_noncuts() - spliter.len_training_cuts())\n",
    "\n",
    "print('Training set length is {0}: {1} cuts vs {2} noncuts'.format(len(spliter.df_training), \n",
    "                                                                       spliter.len_training_cuts(), \n",
    "                                                                       spliter.len_training_noncuts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e84efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_validation = spliter.get_validation_generator(batch_size=16, video_size=(160, 90), rescale=1/255)\n",
    "gen_training = spliter.get_training_generator(batch_size=64, video_size=(160, 90), rescale=1/255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b9d7d",
   "metadata": {},
   "source": [
    "# Build a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3362b4be",
   "metadata": {},
   "source": [
    "Save architecture same as in `Gif Learning Model.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4187e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv3D(32, 3, activation='relu', input_shape=(4, 160, 90, 3)), \n",
    "    tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2)), \n",
    "    tf.keras.layers.Conv3D(64, 2, activation='relu'), \n",
    "    tf.keras.layers.MaxPooling3D(pool_size=(1, 2, 2)), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'), \n",
    "    #tf.keras.layers.Dropout(0.3), \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea97f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 2, 158, 88, 32)    2624      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3  (None, 2, 79, 44, 32)     0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 1, 78, 43, 64)     16448     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPoolin  (None, 1, 39, 21, 64)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 52416)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               6709376   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6728577 (25.67 MB)\n",
      "Trainable params: 6728577 (25.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28a683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 0.9625"
     ]
    }
   ],
   "source": [
    "history = model.fit(gen_validation.flow(),\n",
    "                    steps_per_epoch=len(gen_validation), \n",
    "                    epochs=1,\n",
    "                    verbose=1,\n",
    "                    validation_data=gen_validation.flow(), \n",
    "                    validation_steps=len(gen_validation))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b676706d",
   "metadata": {},
   "source": [
    "history = model.fit(gen_training.flow(),\n",
    "                    steps_per_epoch=len(gen_training), \n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=gen_validation.flow(), \n",
    "                    validation_steps=len(gen_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(history.history['val_loss']) == len(history.epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92e851",
   "metadata": {},
   "source": [
    "# Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce147f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "now = str(now)[:16]\n",
    "\n",
    "print(f'Current date and timie is {now}')\n",
    "now = now.replace(' ', '-').replace(':', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76404498",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = 'models'\n",
    "path_history = 'histories'\n",
    "if not os.path.isdir(path_model):\n",
    "    os.mkdir(path_model)\n",
    "if not os.path.isdir(path_history):\n",
    "    os.mkdir(path_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06646902",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = os.path.join(path_model, f'{now}.h5')\n",
    "path_history = os.path.join(path_history, f'{now}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a00034",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history).to_csv(path_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f09c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e56a3d",
   "metadata": {},
   "source": [
    "# Learning History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5e4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "fig.set_figwidth(10)\n",
    "fig.set_figheight(8)\n",
    "\n",
    "axs[0].set_title('Accuracy')\n",
    "axs[0].plot(history.epoch, history.history['accuracy'], linewidth=4, label='accuracy')\n",
    "axs[0].plot(history.epoch, history.history['val_accuracy'], linewidth=4, label='val_accuracy')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].set_title('Loss')\n",
    "axs[1].plot(history.epoch, history.history['loss'], linewidth=4, label='loss')\n",
    "axs[1].plot(history.epoch, history.history['val_loss'], linewidth=4, label='val_loss')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9c451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
